date
Sun 20 Nov 2022 08:51:50 PM CST

# node info: 192.168.2.66

# registry details
reg_name='192.168.2.100'
reg_port='5000'

# create a cluster with the local registry enabled in containerd
cat <<EOF | kind create cluster --name=cluster2 --image=192.168.2.100:5000/kindest/node:v1.23.4 --config=-
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
networking:
        disableDefaultCNI: true
        podSubnet: "10.20.0.0/16"
        serviceSubnet: "10.21.0.0/16"

nodes:
        - role: control-plane
        - role: worker


containerdConfigPatches:
- |-
  [plugins."io.containerd.grpc.v1.cri".registry.mirrors."${reg_name}:${reg_port}"]
    endpoint = ["http://${reg_name}:5000"]
EOF
Creating cluster "cluster2" ...
 â€¢ Ensuring node image (192.168.2.100:5000/kindest/node:v1.23.4) ðŸ–¼  ...
 âœ“ Ensuring node image (192.168.2.100:5000/kindest/node:v1.23.4) ðŸ–¼
 â€¢ Preparing nodes ðŸ“¦ ðŸ“¦   ...
 âœ“ Preparing nodes ðŸ“¦ ðŸ“¦ 
 â€¢ Writing configuration ðŸ“œ  ...
 âœ“ Writing configuration ðŸ“œ
 â€¢ Starting control-plane ðŸ•¹ï¸  ...
 âœ“ Starting control-plane ðŸ•¹ï¸
 â€¢ Installing StorageClass ðŸ’¾  ...
 âœ“ Installing StorageClass ðŸ’¾
 â€¢ Joining worker nodes ðŸšœ  ...
 âœ“ Joining worker nodes ðŸšœ
Set kubectl context to "kind-cluster2"
You can now use your cluster with:

kubectl cluster-info --context kind-cluster2

Have a nice day! ðŸ‘‹

# prep the environment
controller_node=$(kubectl get nodes --no-headers  -o custom-columns=NAME:.metadata.name| grep control-plane)
kubectl taint nodes $controller_node node-role.kubernetes.io/master:NoSchedule-
node/cluster2-control-plane untainted
kubectl get nodes -owide 
NAME                     STATUS     ROLES                  AGE   VERSION   INTERNAL-IP   EXTERNAL-IP   OS-IMAGE       KERNEL-VERSION      CONTAINER-RUNTIME
cluster2-control-plane   NotReady   control-plane,master   48s   v1.23.4   172.18.0.5    <none>        Ubuntu 21.10   5.15.0-52-generic   containerd://1.5.10
cluster2-worker          NotReady   <none>                 12s   v1.23.4   172.18.0.6    <none>        Ubuntu 21.10   5.15.0-52-generic   containerd://1.5.10
kubectl get pods -owide -A
NAMESPACE            NAME                                             READY   STATUS    RESTARTS   AGE   IP           NODE                     NOMINATED NODE   READINESS GATES
kube-system          coredns-64897985d-crscx                          0/1     Pending   0          30s   <none>       <none>                   <none>           <none>
kube-system          coredns-64897985d-jcvcp                          0/1     Pending   0          30s   <none>       <none>                   <none>           <none>
kube-system          etcd-cluster2-control-plane                      1/1     Running   0          46s   172.18.0.5   cluster2-control-plane   <none>           <none>
kube-system          kube-apiserver-cluster2-control-plane            1/1     Running   0          47s   172.18.0.5   cluster2-control-plane   <none>           <none>
kube-system          kube-controller-manager-cluster2-control-plane   1/1     Running   0          47s   172.18.0.5   cluster2-control-plane   <none>           <none>
kube-system          kube-proxy-nzvxb                                 1/1     Running   0          11s   172.18.0.6   cluster2-worker          <none>           <none>
kube-system          kube-proxy-xgh5s                                 1/1     Running   0          30s   172.18.0.5   cluster2-control-plane   <none>           <none>
kube-system          kube-scheduler-cluster2-control-plane            1/1     Running   0          46s   172.18.0.5   cluster2-control-plane   <none>           <none>
local-path-storage   local-path-provisioner-5ddd94ff66-nlw5p          0/1     Pending   0          30s   <none>       <none>                   <none>           <none>

# install CNI
#helm template cilium cilium/cilium --set k8sServiceHost=$controller_node --set k8sServicePort=6443 --version 1.12.0 --namespace kube-system --set ipam.mode=kubernetes --set cluster.id=2 --set cluster.name=cluster2 > ./cluster2-cilium_vxlan.yaml
#kubectl apply -f ./cluster2-cilium_vxlan.yaml

cilium install --context kind-cluster2 --version v1.12.0 --helm-set ipam.mode=kubernetes,cluster.name=cluster2,cluster.id=2 --inherit-ca kind-cluster1
ðŸ”® Auto-detected Kubernetes kind: kind
âœ¨ Running "kind" validation checks
âœ… Detected kind version "0.17.0"
â„¹ï¸  Using Cilium version 1.12.0
ðŸ”® Auto-detected cluster name: kind-cluster2
ðŸ”® Auto-detected datapath mode: tunnel
â„¹ï¸  helm template --namespace kube-system cilium cilium/cilium --version 1.12.0 --set cluster.id=2,cluster.name=cluster2,encryption.nodeEncryption=false,ipam.mode=kubernetes,kubeProxyReplacement=disabled,operator.replicas=1,serviceAccounts.cilium.name=cilium,serviceAccounts.operator.name=cilium-operator,tunnel=vxlan
â„¹ï¸  Storing helm values file in kube-system/cilium-cli-helm-values Secret
ðŸ”‘ Found CA in secret cilium-ca
ðŸ”‘ Generating certificates for Hubble...
ðŸš€ Creating Service accounts...
ðŸš€ Creating Cluster roles...
ðŸš€ Creating ConfigMap for Cilium version 1.12.0...
ðŸš€ Creating Agent DaemonSet...
ðŸš€ Creating Operator Deployment...
âŒ› Waiting for Cilium to be installed and ready...
â™»ï¸  Restarting unmanaged pods...
â™»ï¸  Restarted unmanaged pod kube-system/coredns-64897985d-crscx
â™»ï¸  Restarted unmanaged pod kube-system/coredns-64897985d-jcvcp
â™»ï¸  Restarted unmanaged pod local-path-storage/local-path-provisioner-5ddd94ff66-nlw5p
âœ… Cilium was successfully installed! Run 'cilium status' to view installation health
cilium status  --context kind-cluster2 --wait
[33m    /Â¯Â¯\
[36m /Â¯Â¯[33m\__/[32mÂ¯Â¯\[0m    Cilium:         [32mOK[0m
[36m \__[31m/Â¯Â¯\[32m__/[0m    Operator:       [32mOK[0m
[32m /Â¯Â¯[31m\__/[35mÂ¯Â¯\[0m    Hubble:         [36mdisabled[0m
[32m \__[34m/Â¯Â¯\[35m__/[0m    ClusterMesh:    [36mdisabled[0m
[34m    \__/
[0m
Deployment        cilium-operator    Desired: 1, Ready: [32m1/1[0m, Available: [32m1/1[0m
DaemonSet         cilium             Desired: 2, Ready: [32m2/2[0m, Available: [32m2/2[0m
Containers:       cilium-operator    Running: [32m1[0m
                  cilium             Running: [32m2[0m
Cluster Pods:     0/6 managed by Cilium
Image versions    cilium             quay.io/cilium/cilium:v1.12.0@sha256:079baa4fa1b9fe638f96084f4e0297c84dd4fb215d29d2321dcbe54273f63ade: 2
                  cilium-operator    quay.io/cilium/operator-generic:v1.12.0@sha256:bb2a42eda766e5d4a87ee8a5433f089db81b72dd04acf6b59fcbb445a95f9410: 1

# prep the necessary tools
for i in $(docker ps  -a --format "table {{.Names}}"|grep cluster2 );
do 
echo $i;
docker cp /usr/bin/ping $i:/usr/bin/ping;
docker cp /usr/bin/cilium $i:/usr/bin/cilium
docker exec -it $i  bash -c "sed -i -e 's/jp.archive.ubuntu.com\|archive.ubuntu.com\|security.ubuntu.com/old-releases.ubuntu.com/g' /etc/apt/sources.list";docker exec -it $i bash -c "apt-get -y update >/dev/null && apt-get -y install net-tools tcpdump >/dev/null"
done
cluster2-control-plane
debconf: delaying package configuration, since apt-utils is not installed
cluster2-worker
debconf: delaying package configuration, since apt-utils is not installed
